apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: upload-data-card-s3
spec:
  params:
    - name: data_card
      type: string
    - name: bucket
      type: string
    - name: s3_url
      type: string
    - name: access_key
      type: string
    - name: secret_key
      type: string
  steps:
    - computeResources: {}
      env:
        - name: DATA_CARD
          value: $(params.data_card)
        - name: BUCKET
          value: $(params.bucket)
        - name: ENDPOINT
          value: $(params.s3_url)
        - name: ACCESS_KEY
          value: $(params.access_key)
        - name: SECRET_KEY
          value: $(params.secret_key)
      image: 'quay.io/rh_ee_akugel/datacard-python:1.1'
      name: echo
      script: |
        #!/usr/bin/env python3

        import boto3
        import botocore
        import os
        from io import BytesIO
        import json
        import botocore.exceptions

        def main():

            aws_access_key_id = os.environ.get("ACCESS_KEY")
            aws_secret_access_key = os.environ.get("SECRET_KEY")
            aws_endpoint = os.environ.get("ENDPOINT")

            s3_client_data_card = boto3.client(
                service_name="s3",
                aws_access_key_id='minio',
                aws_secret_access_key='minio123',
                endpoint_url='https://minio-api-minio.apps.cluster-4ghn9.4ghn9.sandbox2431.opentlc.com',
            )

            s3_client = boto3.client(
                service_name="s3",
                aws_access_key_id=aws_access_key_id,
                aws_secret_access_key=aws_secret_access_key,
                endpoint_url=aws_endpoint,
            )

            # with open("create_event.json", "r") as file:
            #     data = json.load(file)

            target_bucket = os.environ.get("BUCKET")
            data_card_bucket = "data-cards"
            data_card = os.environ.get("DATA_CARD")
            # data = json.loads(os.environ.get("payload_body"))

            # Function to get file details from the source S3 bucket
            def get_file_info(bucket_name):
              file_info = []

              # List all objects in the source bucket
              response = s3_client.list_objects_v2(Bucket=bucket_name)

              if 'Contents' in response:
                  for obj in response['Contents']:
                      file_info.append(
                      {
                          'FileName': obj['Key'],
                          'Size': obj['Size'],
                          'LastModified': obj['LastModified'].strftime('%Y-%m-%d %H:%M:%S'),
                          'ETag': obj['ETag'],
                          'StorageClass': obj['StorageClass'],
                          'SourceBucketUrl': aws_endpoint
                      })
              return file_info

            # Get file info from the source bucket
            file_info = get_file_info(target_bucket)

            try:
                # Check if the object already exists
                s3_client_data_card.head_object(Bucket=data_card_bucket, Key=data_card)
                print(f"File {data_card} already exists in the bucket.")

                # Read the contents of the existing file in S3
                existing_file = s3_client.get_object(Bucket=data_card_bucket, Key=data_card)
                existing_file_content = existing_file["Body"].read().decode("utf-8")
                existing_file_json = json.loads(existing_file_content)

                for event_record in existing_file_json:
                    file_info.append(event_record)

                # Upload the combined content to S3
                s3_client_data_card.put_object(Body=json.dumps(file_info), Bucket=data_card_bucket, Key=data_card, ContentType='application/json')
                print(f"Combined file uploaded to {data_card} in S3.")

            except botocore.exceptions.ClientError as e:
                print("exception caught", e.response["Error"]["Code"])
                # If the object doesn"t exist, upload the new file
                if e.response["Error"]["Code"] == "404":

                    s3_client_data_card.put_object(Body=json.dumps(file_info), Bucket=data_card_bucket, Key=data_card, ContentType='application/json')
                    print(f"Bucket {data_card} created.")

                else:
                    # Reraise other types of errors
                    raise

        if __name__ == "__main__":
            main()
